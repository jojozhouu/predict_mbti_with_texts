random_seed: 100
clean:
  check_dl_nltk_data:
    download_dir: data/nltk
  save_clean_data_to_file:
    clean_data_output_filename: clean_posts
  save_stopwords_to_file:
    stopwords_output_dir: data/stopwords
    stopwords_output_filename: stopwords
train:
  train_wrapper:
    posts_colname: posts
  read_stopwords:
    stopwords_path: data/stopwords/stopwords.csv
  split_data:
    test_size: 0.2
    random_state: 100
  save_split_to_files:
    train_filename: train
    test_filename: test
  create_fit_vectorizer:
    max_features: 5000
  save_vectorizer_to_file:
    vectorizer_filename: tfidf_vectorizer
  train_logit:
    C: 0.5
predict:
  predict_wrapper:
    posts_colname: posts
    y_pred_filename_prefix: prediction
evaluate:
  evaluate_wrapper:
    metrics_output_filename: metric
    y_pred_filename_prefix: prediction
